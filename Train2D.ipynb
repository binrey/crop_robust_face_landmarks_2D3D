{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 11 11:51:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla M40           Off  | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    61W / 250W |    115MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40           Off  | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    60W / 250W |  11026MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla M40           Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    69W / 250W |     11MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla M40           Off  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   24C    P8    16W / 250W |     11MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datatools import Loader2D, Generator, show_xy, Aug2D\n",
    "from traintools import plot_history, get_callbacks, create_dirs\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/media/hdd/public/Datasets/faces/300W\"\n",
    "imsize = (64, 64)\n",
    "used_lmarks = []\n",
    "for i in [8, 30, 36, 39, 42, 45, 48, 54]:\n",
    "    used_lmarks += list(range(i*2, i*2+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = Loader2D(data_dir=os.path.join(data_dir, \"train_crop\"), \n",
    "                        img_size=imsize, \n",
    "                        valid_size=0, \n",
    "                        annotation_file=\"annotations.txt\",\n",
    "                        augmenter=Aug2D(imsize),\n",
    "                        used_lmarks=used_lmarks\n",
    "                       )   \n",
    "loader_valid = Loader2D(data_dir=os.path.join(data_dir, \"test_crop\"), \n",
    "                        img_size=imsize, \n",
    "                        valid_size=1, \n",
    "                        annotation_file=\"annotations.txt\",\n",
    "                        augmenter=Aug2D(imsize),\n",
    "                        used_lmarks=used_lmarks\n",
    "                       )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64, 64, 1) (8, 16)\n",
      "(8, 64, 64, 1) (8, 16)\n",
      "(8, 64, 64, 1) (8, 16)\n"
     ]
    }
   ],
   "source": [
    "# Test generator\n",
    "n = 0\n",
    "for x, y in Generator(loader_train, 8).get_iterator(train=True):\n",
    "    n += 1\n",
    "    print(x.shape, y.shape)\n",
    "    if n >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = loader_train.get_item(loader_train.train_set[np.random.randint(100)])\n",
    "show_xy(x, y)\n",
    "print(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"landmarks-vanilla2d\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "data (InputLayer)                            [(None, 64, 64, 1)]                     0              \n",
      "____________________________________________________________________________________________________\n",
      "lambda (Lambda)                              (None, 64, 64, 1)                       0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_01_conv (Conv2D)                  (None, 64, 64, 16)                      416            \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_01_act (Activation)               (None, 64, 64, 16)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "pool_01 (MaxPooling2D)                       (None, 32, 32, 16)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_02_conv (Conv2D)                  (None, 32, 32, 32)                      4640           \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_02_act (Activation)               (None, 32, 32, 32)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "pool_02 (MaxPooling2D)                       (None, 16, 16, 32)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_03_conv (Conv2D)                  (None, 16, 16, 48)                      13872          \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_03_act (Activation)               (None, 16, 16, 48)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "pool_03 (MaxPooling2D)                       (None, 8, 8, 48)                        0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_04_conv (Conv2D)                  (None, 8, 8, 64)                        27712          \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_04_act (Activation)               (None, 8, 8, 64)                        0              \n",
      "____________________________________________________________________________________________________\n",
      "pool_04 (MaxPooling2D)                       (None, 4, 4, 64)                        0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_05_conv (Conv2D)                  (None, 4, 4, 96)                        55392          \n",
      "____________________________________________________________________________________________________\n",
      "conv_block_05_act (Activation)               (None, 4, 4, 96)                        0              \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                            (None, 1536)                            0              \n",
      "____________________________________________________________________________________________________\n",
      "dense_01 (Dense)                             (None, 136)                             209032         \n",
      "____________________________________________________________________________________________________\n",
      "dense_lmarks (Dense)                         (None, 136)                             18632          \n",
      "====================================================================================================\n",
      "Total params: 329,696\n",
      "Trainable params: 329,696\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from models import vanilla, fconv2d\n",
    "\n",
    "model = vanilla((imsize[1], imsize[0], 1))\n",
    "model.load_weights(\"vanilla-68/checkpoints/model_final.h5\")\n",
    "print(model.summary(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "logdir = create_dirs(\"vanilla-68/\")\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = Generator(loader_train, 128)\n",
    "gen_valid = Generator(loader_valid, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-a28e55b4e8bb>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.2679\n",
      "Epoch 00001: val_loss improved from inf to 0.11355, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.2679 - val_loss: 0.1135 - lr: 0.0020\n",
      "Epoch 2/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.1076\n",
      "Epoch 00002: val_loss improved from 0.11355 to 0.07464, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.1076 - val_loss: 0.0746 - lr: 0.0020\n",
      "Epoch 3/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0847\n",
      "Epoch 00003: val_loss improved from 0.07464 to 0.06831, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0847 - val_loss: 0.0683 - lr: 0.0020\n",
      "Epoch 4/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00004: val_loss did not improve from 0.06831\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0799 - val_loss: 0.0686 - lr: 0.0020\n",
      "Epoch 5/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0803\n",
      "Epoch 00005: val_loss improved from 0.06831 to 0.06635, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0803 - val_loss: 0.0664 - lr: 0.0020\n",
      "Epoch 6/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0788\n",
      "Epoch 00006: val_loss improved from 0.06635 to 0.06586, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0788 - val_loss: 0.0659 - lr: 0.0020\n",
      "Epoch 7/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0770\n",
      "Epoch 00007: val_loss improved from 0.06586 to 0.06261, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0770 - val_loss: 0.0626 - lr: 0.0020\n",
      "Epoch 8/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0733\n",
      "Epoch 00008: val_loss improved from 0.06261 to 0.05988, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0733 - val_loss: 0.0599 - lr: 0.0020\n",
      "Epoch 9/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0646\n",
      "Epoch 00009: val_loss improved from 0.05988 to 0.04793, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0646 - val_loss: 0.0479 - lr: 0.0020\n",
      "Epoch 10/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 00010: val_loss did not improve from 0.04793\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0525 - val_loss: 0.0550 - lr: 0.0020\n",
      "Epoch 11/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0476\n",
      "Epoch 00011: val_loss improved from 0.04793 to 0.04743, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0476 - val_loss: 0.0474 - lr: 0.0020\n",
      "Epoch 12/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 00012: val_loss improved from 0.04743 to 0.03987, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0441 - val_loss: 0.0399 - lr: 0.0020\n",
      "Epoch 13/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0405\n",
      "Epoch 00013: val_loss improved from 0.03987 to 0.03818, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0405 - val_loss: 0.0382 - lr: 0.0020\n",
      "Epoch 14/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0384\n",
      "Epoch 00014: val_loss did not improve from 0.03818\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0384 - val_loss: 0.0393 - lr: 0.0020\n",
      "Epoch 15/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0365\n",
      "Epoch 00015: val_loss did not improve from 0.03818\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0365 - val_loss: 0.0385 - lr: 0.0020\n",
      "Epoch 16/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 00016: val_loss improved from 0.03818 to 0.03514, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0357 - val_loss: 0.0351 - lr: 0.0020\n",
      "Epoch 17/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 00017: val_loss improved from 0.03514 to 0.03173, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0352 - val_loss: 0.0317 - lr: 0.0020\n",
      "Epoch 18/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 00018: val_loss improved from 0.03173 to 0.03113, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0330 - val_loss: 0.0311 - lr: 0.0020\n",
      "Epoch 19/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 00019: val_loss improved from 0.03113 to 0.03050, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0331 - val_loss: 0.0305 - lr: 0.0020\n",
      "Epoch 20/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 00020: val_loss did not improve from 0.03050\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0316 - val_loss: 0.0332 - lr: 0.0020\n",
      "Epoch 21/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 00021: val_loss improved from 0.03050 to 0.03002, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0311 - val_loss: 0.0300 - lr: 0.0020\n",
      "Epoch 22/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0313\n",
      "Epoch 00022: val_loss improved from 0.03002 to 0.02960, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0313 - val_loss: 0.0296 - lr: 0.0020\n",
      "Epoch 23/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 00023: val_loss did not improve from 0.02960\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0297 - val_loss: 0.0299 - lr: 0.0020\n",
      "Epoch 24/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0301\n",
      "Epoch 00024: val_loss improved from 0.02960 to 0.02888, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0301 - val_loss: 0.0289 - lr: 0.0020\n",
      "Epoch 25/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0289\n",
      "Epoch 00025: val_loss did not improve from 0.02888\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0289 - val_loss: 0.0289 - lr: 0.0020\n",
      "Epoch 26/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 00026: val_loss did not improve from 0.02888\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0280 - val_loss: 0.0316 - lr: 0.0020\n",
      "Epoch 27/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 00027: val_loss did not improve from 0.02888\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0283 - val_loss: 0.0302 - lr: 0.0020\n",
      "Epoch 28/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 00028: val_loss improved from 0.02888 to 0.02800, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0280 - val_loss: 0.0280 - lr: 0.0020\n",
      "Epoch 29/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 00029: val_loss did not improve from 0.02800\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0266 - val_loss: 0.0288 - lr: 0.0020\n",
      "Epoch 30/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 00030: val_loss did not improve from 0.02800\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0271 - val_loss: 0.0312 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 00031: val_loss improved from 0.02800 to 0.02579, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0255 - val_loss: 0.0258 - lr: 0.0020\n",
      "Epoch 32/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 00032: val_loss did not improve from 0.02579\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0260 - val_loss: 0.0266 - lr: 0.0020\n",
      "Epoch 33/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 00033: val_loss did not improve from 0.02579\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0248 - val_loss: 0.0265 - lr: 0.0020\n",
      "Epoch 34/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 00034: val_loss improved from 0.02579 to 0.02432, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0247 - val_loss: 0.0243 - lr: 0.0020\n",
      "Epoch 35/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00035: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0251 - val_loss: 0.0251 - lr: 0.0020\n",
      "Epoch 36/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00036: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0253 - val_loss: 0.0279 - lr: 0.0020\n",
      "Epoch 37/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0246\n",
      "Epoch 00037: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0246 - val_loss: 0.0252 - lr: 0.0020\n",
      "Epoch 38/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 00038: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0237 - val_loss: 0.0244 - lr: 0.0020\n",
      "Epoch 39/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 00039: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0249 - val_loss: 0.0253 - lr: 0.0020\n",
      "Epoch 40/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 00040: val_loss did not improve from 0.02432\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0248 - val_loss: 0.0249 - lr: 0.0020\n",
      "Epoch 41/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0236\n",
      "Epoch 00041: val_loss improved from 0.02432 to 0.02353, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0236 - val_loss: 0.0235 - lr: 0.0020\n",
      "Epoch 42/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 00042: val_loss improved from 0.02353 to 0.02309, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0228 - val_loss: 0.0231 - lr: 0.0020\n",
      "Epoch 43/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 00043: val_loss improved from 0.02309 to 0.02225, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0229 - val_loss: 0.0223 - lr: 0.0020\n",
      "Epoch 44/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 00044: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0225 - val_loss: 0.0243 - lr: 0.0020\n",
      "Epoch 45/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 00045: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0225 - val_loss: 0.0229 - lr: 0.0020\n",
      "Epoch 46/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 00046: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0220 - val_loss: 0.0229 - lr: 0.0020\n",
      "Epoch 47/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 00047: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0224 - val_loss: 0.0254 - lr: 0.0020\n",
      "Epoch 48/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0221\n",
      "Epoch 00048: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0221 - val_loss: 0.0224 - lr: 0.0020\n",
      "Epoch 49/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 00049: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0224 - val_loss: 0.0229 - lr: 0.0020\n",
      "Epoch 50/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00050: val_loss did not improve from 0.02225\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0216 - val_loss: 0.0234 - lr: 0.0020\n",
      "Epoch 51/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 00051: val_loss improved from 0.02225 to 0.02168, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0218 - val_loss: 0.0217 - lr: 0.0020\n",
      "Epoch 52/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 00052: val_loss did not improve from 0.02168\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0211 - val_loss: 0.0223 - lr: 0.0020\n",
      "Epoch 53/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 00053: val_loss did not improve from 0.02168\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0217 - val_loss: 0.0226 - lr: 0.0020\n",
      "Epoch 54/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0213\n",
      "Epoch 00054: val_loss did not improve from 0.02168\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0213 - val_loss: 0.0220 - lr: 0.0020\n",
      "Epoch 55/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0221\n",
      "Epoch 00055: val_loss did not improve from 0.02168\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0221 - val_loss: 0.0220 - lr: 0.0020\n",
      "Epoch 56/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0213\n",
      "Epoch 00056: val_loss did not improve from 0.02168\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0213 - val_loss: 0.0228 - lr: 0.0020\n",
      "Epoch 57/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 00057: val_loss improved from 0.02168 to 0.02107, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0209 - val_loss: 0.0211 - lr: 0.0020\n",
      "Epoch 58/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 00058: val_loss did not improve from 0.02107\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0211 - val_loss: 0.0213 - lr: 0.0020\n",
      "Epoch 59/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00059: val_loss did not improve from 0.02107\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0205 - val_loss: 0.0212 - lr: 0.0020\n",
      "Epoch 60/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 00060: val_loss did not improve from 0.02107\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0203 - val_loss: 0.0214 - lr: 0.0020\n",
      "Epoch 61/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 00061: val_loss improved from 0.02107 to 0.02093, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0203 - val_loss: 0.0209 - lr: 0.0020\n",
      "Epoch 62/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00062: val_loss did not improve from 0.02093\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0202 - val_loss: 0.0222 - lr: 0.0020\n",
      "Epoch 63/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00063: val_loss improved from 0.02093 to 0.02069, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0202 - val_loss: 0.0207 - lr: 0.0020\n",
      "Epoch 64/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00064: val_loss did not improve from 0.02069\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0205 - val_loss: 0.0211 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 00065: val_loss improved from 0.02069 to 0.02030, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0203 - val_loss: 0.0203 - lr: 0.0020\n",
      "Epoch 66/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 00066: val_loss did not improve from 0.02030\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0200 - val_loss: 0.0206 - lr: 0.0020\n",
      "Epoch 67/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00067: val_loss improved from 0.02030 to 0.01998, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0195 - val_loss: 0.0200 - lr: 0.0020\n",
      "Epoch 68/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00068: val_loss did not improve from 0.01998\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0199 - val_loss: 0.0208 - lr: 0.0020\n",
      "Epoch 69/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 00069: val_loss did not improve from 0.01998\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0190 - val_loss: 0.0205 - lr: 0.0020\n",
      "Epoch 70/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 00070: val_loss did not improve from 0.01998\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0193 - val_loss: 0.0202 - lr: 0.0020\n",
      "Epoch 71/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00071: val_loss improved from 0.01998 to 0.01950, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0194 - val_loss: 0.0195 - lr: 0.0020\n",
      "Epoch 72/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00072: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0195 - val_loss: 0.0209 - lr: 0.0020\n",
      "Epoch 73/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00073: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0194 - val_loss: 0.0226 - lr: 0.0020\n",
      "Epoch 74/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 00074: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0199 - val_loss: 0.0197 - lr: 0.0020\n",
      "Epoch 75/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00075: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0194 - val_loss: 0.0206 - lr: 0.0020\n",
      "Epoch 76/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 00076: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0190 - val_loss: 0.0206 - lr: 0.0020\n",
      "Epoch 77/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 00077: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0189 - val_loss: 0.0197 - lr: 0.0020\n",
      "Epoch 78/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00078: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0186 - val_loss: 0.0202 - lr: 0.0020\n",
      "Epoch 79/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 00079: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0189 - val_loss: 0.0197 - lr: 0.0020\n",
      "Epoch 80/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 00080: val_loss did not improve from 0.01950\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0187 - val_loss: 0.0195 - lr: 0.0020\n",
      "Epoch 81/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 00081: val_loss improved from 0.01950 to 0.01949, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0188 - val_loss: 0.0195 - lr: 0.0020\n",
      "Epoch 82/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00082: val_loss improved from 0.01949 to 0.01860, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0186 - val_loss: 0.0186 - lr: 0.0020\n",
      "Epoch 83/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00083: val_loss did not improve from 0.01860\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0186 - val_loss: 0.0213 - lr: 0.0020\n",
      "Epoch 84/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00084: val_loss did not improve from 0.01860\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0183 - val_loss: 0.0192 - lr: 0.0020\n",
      "Epoch 85/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00085: val_loss did not improve from 0.01860\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0183 - val_loss: 0.0188 - lr: 0.0020\n",
      "Epoch 86/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00086: val_loss did not improve from 0.01860\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0180 - val_loss: 0.0193 - lr: 0.0020\n",
      "Epoch 87/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00087: val_loss improved from 0.01860 to 0.01839, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0180 - val_loss: 0.0184 - lr: 0.0020\n",
      "Epoch 88/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00088: val_loss did not improve from 0.01839\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0186 - val_loss: 0.0194 - lr: 0.0020\n",
      "Epoch 89/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00089: val_loss did not improve from 0.01839\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0182 - val_loss: 0.0210 - lr: 0.0020\n",
      "Epoch 90/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00090: val_loss did not improve from 0.01839\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0183 - val_loss: 0.0203 - lr: 0.0020\n",
      "Epoch 91/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00091: val_loss improved from 0.01839 to 0.01821, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0183 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 92/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 00092: val_loss did not improve from 0.01821\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0183 - val_loss: 0.0192 - lr: 0.0020\n",
      "Epoch 93/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 00093: val_loss did not improve from 0.01821\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0176 - val_loss: 0.0187 - lr: 0.0020\n",
      "Epoch 94/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 00094: val_loss did not improve from 0.01821\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0178 - val_loss: 0.0187 - lr: 0.0020\n",
      "Epoch 95/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00095: val_loss improved from 0.01821 to 0.01798, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0182 - val_loss: 0.0180 - lr: 0.0020\n",
      "Epoch 96/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 00096: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0178 - val_loss: 0.0186 - lr: 0.0020\n",
      "Epoch 97/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 00097: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0178 - val_loss: 0.0220 - lr: 0.0020\n",
      "Epoch 98/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00098: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0186 - val_loss: 0.0192 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00099: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0177 - val_loss: 0.0192 - lr: 0.0020\n",
      "Epoch 100/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00100: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0181 - val_loss: 0.0202 - lr: 0.0020\n",
      "Epoch 101/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 00101: val_loss did not improve from 0.01798\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0182 - val_loss: 0.0202 - lr: 0.0020\n",
      "Epoch 102/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 00102: val_loss improved from 0.01798 to 0.01770, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0179 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 103/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 00103: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0175 - val_loss: 0.0208 - lr: 0.0020\n",
      "Epoch 104/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 00104: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0175 - val_loss: 0.0198 - lr: 0.0020\n",
      "Epoch 105/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 00105: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0180 - val_loss: 0.0211 - lr: 0.0020\n",
      "Epoch 106/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 00106: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0176 - val_loss: 0.0189 - lr: 0.0020\n",
      "Epoch 107/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 00107: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0175 - val_loss: 0.0181 - lr: 0.0020\n",
      "Epoch 108/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00108: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0177 - val_loss: 0.0188 - lr: 0.0020\n",
      "Epoch 109/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00109: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0170 - val_loss: 0.0180 - lr: 0.0020\n",
      "Epoch 110/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 00110: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0174 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 111/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 00111: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0168 - val_loss: 0.0185 - lr: 0.0020\n",
      "Epoch 112/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 00112: val_loss did not improve from 0.01770\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0172 - val_loss: 0.0183 - lr: 0.0020\n",
      "Epoch 113/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 00113: val_loss improved from 0.01770 to 0.01737, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0172 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 114/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00114: val_loss improved from 0.01737 to 0.01730, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0170 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 115/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 00115: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0173 - val_loss: 0.0197 - lr: 0.0020\n",
      "Epoch 116/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00116: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0166 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 117/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00117: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0167 - val_loss: 0.0180 - lr: 0.0020\n",
      "Epoch 118/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 00118: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0174 - val_loss: 0.0179 - lr: 0.0020\n",
      "Epoch 119/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 00119: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0171 - val_loss: 0.0190 - lr: 0.0020\n",
      "Epoch 120/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 00120: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0172 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 121/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00121: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0167 - val_loss: 0.0188 - lr: 0.0020\n",
      "Epoch 122/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00122: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0170 - val_loss: 0.0178 - lr: 0.0020\n",
      "Epoch 123/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00123: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0167 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 124/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 00124: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0169 - val_loss: 0.0190 - lr: 0.0020\n",
      "Epoch 125/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00125: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0165 - val_loss: 0.0194 - lr: 0.0020\n",
      "Epoch 126/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00126: val_loss did not improve from 0.01730\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0165 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 127/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00127: val_loss improved from 0.01730 to 0.01719, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0162 - val_loss: 0.0172 - lr: 0.0020\n",
      "Epoch 128/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00128: val_loss improved from 0.01719 to 0.01654, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0166 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 129/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00129: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0164 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 130/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00130: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0162 - val_loss: 0.0188 - lr: 0.0020\n",
      "Epoch 131/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00131: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0162 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 132/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00132: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0164 - val_loss: 0.0180 - lr: 0.0020\n",
      "Epoch 133/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00133: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0166 - val_loss: 0.0176 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00134: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0161 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 135/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00135: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0164 - val_loss: 0.0172 - lr: 0.0020\n",
      "Epoch 136/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00136: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0162 - val_loss: 0.0186 - lr: 0.0020\n",
      "Epoch 137/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00137: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0167 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 138/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00138: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0164 - val_loss: 0.0169 - lr: 0.0020\n",
      "Epoch 139/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00139: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0161 - val_loss: 0.0170 - lr: 0.0020\n",
      "Epoch 140/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00140: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0164 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 141/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 00141: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0166 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 142/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00142: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0162 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 143/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00143: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0160 - val_loss: 0.0189 - lr: 0.0020\n",
      "Epoch 144/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 00144: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0164 - val_loss: 0.0194 - lr: 0.0020\n",
      "Epoch 145/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00145: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0163 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 146/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00146: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0157 - val_loss: 0.0180 - lr: 0.0020\n",
      "Epoch 147/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00147: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0159 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 148/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00148: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0162 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 149/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00149: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0163 - val_loss: 0.0187 - lr: 0.0020\n",
      "Epoch 150/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00150: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0160 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 151/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00151: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0161 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 152/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00152: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0159 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 153/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00153: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0158 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 154/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00154: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0162 - val_loss: 0.0175 - lr: 0.0020\n",
      "Epoch 155/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00155: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0160 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 156/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00156: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0157 - val_loss: 0.0182 - lr: 0.0020\n",
      "Epoch 157/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00157: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0163 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 158/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00158: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0163 - val_loss: 0.0181 - lr: 0.0020\n",
      "Epoch 159/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00159: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0157 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 160/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00160: val_loss did not improve from 0.01654\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0157 - val_loss: 0.0175 - lr: 0.0020\n",
      "Epoch 161/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00161: val_loss improved from 0.01654 to 0.01645, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0159 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 162/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00162: val_loss did not improve from 0.01645\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0161 - val_loss: 0.0176 - lr: 0.0020\n",
      "Epoch 163/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00163: val_loss did not improve from 0.01645\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0156 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 164/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00164: val_loss improved from 0.01645 to 0.01617, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0155 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 165/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00165: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0158 - val_loss: 0.0170 - lr: 0.0020\n",
      "Epoch 166/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00166: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0156 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 167/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00167: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0156 - val_loss: 0.0184 - lr: 0.0020\n",
      "Epoch 168/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00168: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0158 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 169/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00169: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0156 - val_loss: 0.0169 - lr: 0.0020\n",
      "Epoch 170/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00170: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0157 - val_loss: 0.0172 - lr: 0.0020\n",
      "Epoch 171/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00171: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0154 - val_loss: 0.0171 - lr: 0.0020\n",
      "Epoch 172/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00172: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0157 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 173/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00173: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0153 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 174/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00174: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0160 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 175/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00175: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0158 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 176/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00176: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0154 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 177/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00177: val_loss did not improve from 0.01617\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0154 - val_loss: 0.0186 - lr: 0.0020\n",
      "Epoch 178/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 00178: val_loss improved from 0.01617 to 0.01611, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0158 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 179/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00179: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0157 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 180/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00180: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0156 - val_loss: 0.0179 - lr: 0.0020\n",
      "Epoch 181/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00181: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0155 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 182/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00182: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0153 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 183/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00183: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0153 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 184/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00184: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0151 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 185/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00185: val_loss did not improve from 0.01611\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0153 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 186/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00186: val_loss improved from 0.01611 to 0.01573, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 187/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00187: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0154 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 188/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00188: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0153 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 189/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00189: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0168 - lr: 0.0020\n",
      "Epoch 190/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00190: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0156 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 191/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00191: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0153 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 192/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00192: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0155 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 193/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00193: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0154 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 194/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00194: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0156 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 195/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00195: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0155 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 196/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00196: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0151 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 197/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00197: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 198/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00198: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 199/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00199: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 200/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00200: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0155 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 201/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00201: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0151 - val_loss: 0.0169 - lr: 0.0020\n",
      "Epoch 202/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00202: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0154 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 203/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00203: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0154 - val_loss: 0.0170 - lr: 0.0020\n",
      "Epoch 204/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00204: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 205/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00205: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0149 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 206/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00206: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0154 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 207/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00207: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0155 - val_loss: 0.0187 - lr: 0.0020\n",
      "Epoch 208/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00208: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 209/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00209: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0160 - lr: 0.0020\n",
      "Epoch 210/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00210: val_loss did not improve from 0.01573\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0148 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 211/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00211: val_loss improved from 0.01573 to 0.01538, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 212/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00212: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 213/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00213: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 214/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00214: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0147 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 215/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00215: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0175 - lr: 0.0020\n",
      "Epoch 216/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00216: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0148 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 217/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00217: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0151 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 218/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00218: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0150 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 219/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00219: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0179 - lr: 0.0020\n",
      "Epoch 220/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00220: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0151 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 221/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00221: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 222/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00222: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 223/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00223: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0146 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 224/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00224: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0170 - lr: 0.0020\n",
      "Epoch 225/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00225: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0169 - lr: 0.0020\n",
      "Epoch 226/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00226: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 227/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00227: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0173 - lr: 0.0020\n",
      "Epoch 228/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00228: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0150 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 229/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00229: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0172 - lr: 0.0020\n",
      "Epoch 230/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00230: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 231/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00231: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0151 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 232/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00232: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0153 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 233/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00233: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0156 - val_loss: 0.0189 - lr: 0.0020\n",
      "Epoch 234/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00234: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 235/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00235: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 236/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00236: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0147 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 237/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00237: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0147 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 238/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00238: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0145 - val_loss: 0.0169 - lr: 0.0020\n",
      "Epoch 239/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00239: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0159 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00240: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 241/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00241: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 242/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00242: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0145 - val_loss: 0.0168 - lr: 0.0020\n",
      "Epoch 243/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00243: val_loss did not improve from 0.01538\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 244/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00244: val_loss improved from 0.01538 to 0.01527, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 245/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00245: val_loss improved from 0.01527 to 0.01526, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0142 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 246/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00246: val_loss did not improve from 0.01526\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0142 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 247/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00247: val_loss did not improve from 0.01526\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 248/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00248: val_loss did not improve from 0.01526\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0146 - val_loss: 0.0160 - lr: 0.0020\n",
      "Epoch 249/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00249: val_loss did not improve from 0.01526\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0147 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 250/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00250: val_loss improved from 0.01526 to 0.01514, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0144 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 251/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00251: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0147 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 252/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00252: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0148 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 253/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00253: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 254/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00254: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0148 - val_loss: 0.0166 - lr: 0.0020\n",
      "Epoch 255/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00255: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0147 - val_loss: 0.0174 - lr: 0.0020\n",
      "Epoch 256/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 00256: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0150 - val_loss: 0.0160 - lr: 0.0020\n",
      "Epoch 257/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00257: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 258/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00258: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0144 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 259/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00259: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0145 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 260/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00260: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0148 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 261/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00261: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0142 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 262/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00262: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0147 - val_loss: 0.0165 - lr: 0.0020\n",
      "Epoch 263/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00263: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0144 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 264/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00264: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0143 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 265/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00265: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0139 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 266/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00266: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0145 - val_loss: 0.0170 - lr: 0.0020\n",
      "Epoch 267/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 00267: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0148 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 268/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00268: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 269/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00269: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0149 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 270/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 00270: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0147 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 271/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00271: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0145 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 272/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00272: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0146 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 273/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00273: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0144 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 274/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00274: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0146 - val_loss: 0.0156 - lr: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00275: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0145 - val_loss: 0.0160 - lr: 0.0020\n",
      "Epoch 276/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00276: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0144 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 277/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00277: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 278/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00278: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 279/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00279: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0145 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 280/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00280: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0149 - val_loss: 0.0167 - lr: 0.0020\n",
      "Epoch 281/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00281: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0142 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 282/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00282: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 283/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00283: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0138 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 284/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00284: val_loss did not improve from 0.01514\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0142 - val_loss: 0.0161 - lr: 0.0020\n",
      "Epoch 285/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00285: val_loss improved from 0.01514 to 0.01497, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0150 - lr: 0.0020\n",
      "Epoch 286/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00286: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 287/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00287: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0140 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 288/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00288: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0138 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 289/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00289: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 290/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00290: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0144 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 291/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00291: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0145 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 292/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00292: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0157 - lr: 0.0020\n",
      "Epoch 293/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00293: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0142 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 294/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00294: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0142 - val_loss: 0.0160 - lr: 0.0020\n",
      "Epoch 295/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00295: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0144 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 296/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00296: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0154 - lr: 0.0020\n",
      "Epoch 297/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00297: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0138 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 298/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00298: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 299/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00299: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 300/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00300: val_loss did not improve from 0.01497\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 301/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00301: val_loss improved from 0.01497 to 0.01487, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0140 - val_loss: 0.0149 - lr: 0.0020\n",
      "Epoch 302/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00302: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0164 - lr: 0.0020\n",
      "Epoch 303/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00303: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0140 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 304/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00304: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0179 - lr: 0.0020\n",
      "Epoch 305/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00305: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0141 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 306/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00306: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0144 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 307/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00307: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0139 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 308/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00308: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0150 - lr: 0.0020\n",
      "Epoch 309/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00309: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 310/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00310: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 311/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00311: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 312/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00312: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0163 - lr: 0.0020\n",
      "Epoch 313/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00313: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 314/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00314: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0141 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 315/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00315: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 316/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00316: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0142 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 317/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00317: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0137 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 318/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00318: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0162 - lr: 0.0020\n",
      "Epoch 319/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00319: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 320/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00320: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 321/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00321: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0139 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 322/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00322: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0143 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 323/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00323: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0177 - lr: 0.0020\n",
      "Epoch 324/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 00324: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0142 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 325/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00325: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0144 - val_loss: 0.0158 - lr: 0.0020\n",
      "Epoch 326/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00326: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 327/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00327: val_loss did not improve from 0.01487\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0137 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 328/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00328: val_loss improved from 0.01487 to 0.01471, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0137 - val_loss: 0.0147 - lr: 0.0020\n",
      "Epoch 329/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00329: val_loss did not improve from 0.01471\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0149 - lr: 0.0020\n",
      "Epoch 330/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00330: val_loss improved from 0.01471 to 0.01464, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0140 - val_loss: 0.0146 - lr: 0.0020\n",
      "Epoch 331/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00331: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0159 - lr: 0.0020\n",
      "Epoch 332/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00332: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0139 - val_loss: 0.0149 - lr: 0.0020\n",
      "Epoch 333/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00333: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0136 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 334/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00334: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0136 - val_loss: 0.0147 - lr: 0.0020\n",
      "Epoch 335/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00335: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0139 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 336/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00336: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 337/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00337: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0137 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 338/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00338: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0138 - val_loss: 0.0147 - lr: 0.0020\n",
      "Epoch 339/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00339: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0138 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 340/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00340: val_loss did not improve from 0.01464\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0138 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 341/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00341: val_loss improved from 0.01464 to 0.01427, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0140 - val_loss: 0.0143 - lr: 0.0020\n",
      "Epoch 342/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00342: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0139 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 343/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00343: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0141 - val_loss: 0.0150 - lr: 0.0020\n",
      "Epoch 344/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 00344: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0144 - val_loss: 0.0155 - lr: 0.0020\n",
      "Epoch 345/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00345: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0139 - val_loss: 0.0153 - lr: 0.0020\n",
      "Epoch 346/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00346: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0139 - val_loss: 0.0156 - lr: 0.0020\n",
      "Epoch 347/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00347: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0140 - val_loss: 0.0148 - lr: 0.0020\n",
      "Epoch 348/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 00348: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0139 - val_loss: 0.0149 - lr: 0.0020\n",
      "Epoch 349/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00349: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0137 - val_loss: 0.0152 - lr: 0.0020\n",
      "Epoch 350/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 00350: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0140 - val_loss: 0.0151 - lr: 0.0020\n",
      "Epoch 351/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 00351: val_loss did not improve from 0.01427\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0131 - val_loss: 0.0145 - lr: 2.0000e-04\n",
      "Epoch 352/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 00352: val_loss improved from 0.01427 to 0.01426, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0128 - val_loss: 0.0143 - lr: 2.0000e-04\n",
      "Epoch 353/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00353: val_loss did not improve from 0.01426\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0125 - val_loss: 0.0144 - lr: 2.0000e-04\n",
      "Epoch 354/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00354: val_loss did not improve from 0.01426\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0125 - val_loss: 0.0143 - lr: 2.0000e-04\n",
      "Epoch 355/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00355: val_loss improved from 0.01426 to 0.01407, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0124 - val_loss: 0.0141 - lr: 2.0000e-04\n",
      "Epoch 356/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00356: val_loss did not improve from 0.01407\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0123 - val_loss: 0.0144 - lr: 2.0000e-04\n",
      "Epoch 357/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00357: val_loss did not improve from 0.01407\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0125 - val_loss: 0.0142 - lr: 2.0000e-04\n",
      "Epoch 358/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00358: val_loss did not improve from 0.01407\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0124 - val_loss: 0.0142 - lr: 2.0000e-04\n",
      "Epoch 359/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00359: val_loss did not improve from 0.01407\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0142 - lr: 2.0000e-04\n",
      "Epoch 360/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00360: val_loss did not improve from 0.01407\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0125 - val_loss: 0.0141 - lr: 2.0000e-04\n",
      "Epoch 361/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00361: val_loss improved from 0.01407 to 0.01388, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 362/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00362: val_loss did not improve from 0.01388\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0142 - lr: 2.0000e-04\n",
      "Epoch 363/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00363: val_loss did not improve from 0.01388\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 364/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00364: val_loss did not improve from 0.01388\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0123 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 365/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00365: val_loss improved from 0.01388 to 0.01387, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0123 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 366/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00366: val_loss improved from 0.01387 to 0.01385, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 367/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00367: val_loss did not improve from 0.01385\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 368/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00368: val_loss did not improve from 0.01385\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 369/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00369: val_loss improved from 0.01385 to 0.01384, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0123 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 370/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00370: val_loss did not improve from 0.01384\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 371/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00371: val_loss did not improve from 0.01384\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 372/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00372: val_loss improved from 0.01384 to 0.01380, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 373/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00373: val_loss did not improve from 0.01380\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 374/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00374: val_loss did not improve from 0.01380\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0121 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 375/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00375: val_loss did not improve from 0.01380\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0143 - lr: 2.0000e-04\n",
      "Epoch 376/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00376: val_loss did not improve from 0.01380\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 377/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00377: val_loss improved from 0.01380 to 0.01377, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 378/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00378: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0121 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 379/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00379: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 380/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00380: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0120 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 381/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00381: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 382/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00382: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0121 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 383/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00383: val_loss improved from 0.01377 to 0.01377, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0123 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 384/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00384: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 385/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00385: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0121 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 386/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00386: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 387/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00387: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0121 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 388/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00388: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0121 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 389/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00389: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 390/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00390: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0120 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 391/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00391: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 392/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00392: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0120 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 393/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00393: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 394/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00394: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0138 - lr: 2.0000e-04\n",
      "Epoch 395/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00395: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0123 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 396/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00396: val_loss did not improve from 0.01377\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0120 - val_loss: 0.0139 - lr: 2.0000e-04\n",
      "Epoch 397/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00397: val_loss improved from 0.01377 to 0.01373, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0121 - val_loss: 0.0137 - lr: 2.0000e-04\n",
      "Epoch 398/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00398: val_loss did not improve from 0.01373\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0121 - val_loss: 0.0140 - lr: 2.0000e-04\n",
      "Epoch 399/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00399: val_loss did not improve from 0.01373\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0122 - val_loss: 0.0137 - lr: 2.0000e-04\n",
      "Epoch 400/400\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00400: val_loss improved from 0.01373 to 0.01373, saving model to ./fconv2d-8-scaled/checkpoints/model.h5\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0122 - val_loss: 0.0137 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=gen_train.get_iterator(train=True),\n",
    "                              steps_per_epoch=20,\n",
    "                              epochs=400,\n",
    "                              initial_epoch=0,\n",
    "                              validation_data=gen_valid.get_iterator(train=False),\n",
    "                              validation_steps=25,\n",
    "                              callbacks=get_callbacks(logdir, 0.002, 350),\n",
    "                              use_multiprocessing=False\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(os.path.join(logdir, \"checkpoints\", \"model_final.h5\"))\n",
    "plot_history(logdir, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0136\n",
      "CPU times: user 2.82 s, sys: 156 ms, total: 2.98 s\n",
      "Wall time: 2.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013635175302624702"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# CALC TEST METRICS WITHOUT AUGMENTATION\n",
    "gen_test = Generator(loader_valid, 7)\n",
    "model.evaluate(gen_test.get_iterator(train=False), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader_valid.do_augmentation = True\n",
    "item_id = np.random.randint(100)\n",
    "x, y = loader_valid.get_item(loader_valid.valid_set[item_id])\n",
    "\n",
    "lmarks = model.predict(np.expand_dims(x, 0)).flatten()\n",
    "#print(model.evaluate(np.expand_dims(x, 0), np.expand_dims(y, 0), steps=1, verbose=0))\n",
    "show_xy(x, y, lmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Output images are placed in ./croptest_out folder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from testtools import CropTester\n",
    "def keras_wrapper(img_crop):\n",
    "    \"\"\"\n",
    "    input img_crop: face crop before resize\n",
    "    output: landmarks as flatten np.array\n",
    "    \"\"\"\n",
    "    net_input = cv2.cvtColor(img_crop, cv2.COLOR_BGR2GRAY)\n",
    "    net_input = cv2.resize(net_input, model.input_shape[1:-1][::-1])\n",
    "    net_input = net_input.reshape(1, net_input.shape[0], net_input.shape[1], 1)\n",
    "    lmarks = model.predict(net_input)\n",
    "    return lmarks\n",
    "\n",
    "ct = CropTester(keras_wrapper, num_iterations=5, pad_min_max=(0.0, 0.), crop_type=\"rand\", rseed=1)\n",
    "#ct.test_image(\"/media/hdd/public/Datasets/faces/300W/test_crop/ibug/000385.png\")\n",
    "ct.test_image(\"/media/hdd/public/Datasets/faces/300W/test_crop/helen/000022.png\", color=(255, 0, 0))\n",
    "\n",
    "ct.mean_pixel_std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fconv2d((imsize[1], imsize[0], 1), 8, train_mode=False)\n",
    "model.load_weights(os.path.join(logdir, \"checkpoints/model_final.h5\"), by_name=True)\n",
    "model.save(os.path.join(logdir, \"checkpoints/model_infer.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "subprocess.Popen([r\"/bin/bash\"])\n",
    "process_params = [r\"{}\".format(sys.executable),\n",
    "                  r\"freeze_graph.py\",\n",
    "                  r\"{}\".format(os.path.join(logdir, \"checkpoints/model_infer.h5\"))]\n",
    "res = subprocess.Popen(process_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3.7'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  7 13:52:38 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla M40           Off  | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    61W / 250W |  10880MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla M40           Off  | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    60W / 250W |    292MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla M40           Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   22C    P8    17W / 250W |     11MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla M40           Off  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   23C    P8    16W / 250W |     11MiB / 11448MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2022-04-07 13:52:54.271506: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-04-07 13:52:54.290433: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200015000 Hz\n",
      "2022-04-07 13:52:54.296906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4962790 executing computations on platform Host. Devices:\n",
      "2022-04-07 13:52:54.296961: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-04-07 13:52:54.301730: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 13:52:54.515532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a13a50 executing computations on platform CUDA. Devices:\n",
      "2022-04-07 13:52:54.515590: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla M40, Compute Capability 5.2\n",
      "2022-04-07 13:52:54.516815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla M40 major: 5 minor: 2 memoryClockRate(GHz): 1.112\n",
      "pciBusID: 0000:03:00.0\n",
      "2022-04-07 13:52:54.517233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-04-07 13:52:54.519057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-04-07 13:52:54.521065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-04-07 13:52:54.521674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-04-07 13:52:54.524627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-04-07 13:52:54.526902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-04-07 13:52:54.533568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 13:52:54.536414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2022-04-07 13:52:54.536491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-04-07 13:52:54.538664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 13:52:54.538701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2022-04-07 13:52:54.538718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2022-04-07 13:52:54.541889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10498 MB memory) -> physical GPU (device: 0, name: Tesla M40, pci bus id: 0000:03:00.0, compute capability: 5.2)\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From freeze_graph.py:50: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/tools/optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization/FusedBatchNorm'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"freeze_graph.py\", line 58, in <module>\r\n",
      "    test_input = np.ones((1,) + model.input.shape[1:])\r\n",
      "TypeError: can only concatenate tuple (not \"TensorShape\") to tuple\r\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3.7 freeze_graph.py bn_tuning/checkpoints/model_infer.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.3.0-tf\n",
      "/usr/bin/python3.7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
